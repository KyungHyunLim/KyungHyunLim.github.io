<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>Precourse 수학기초</title>
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Precourse 수학기초 | AI Tech Study</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Precourse 수학기초" />
<meta name="author" content="LKH" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. Numpy / 벡터 &amp; 행렬 1.1 Numerical Python - Numpy 기본적으로 파이썬 리스트는 메모리 주소 복사 fancy index" />
<meta property="og:description" content="1. Numpy / 벡터 &amp; 행렬 1.1 Numerical Python - Numpy 기본적으로 파이썬 리스트는 메모리 주소 복사 fancy index" />
<meta property="og:site_name" content="AI Tech Study" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-24T01:20:56+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Precourse 수학기초" />
<script type="application/ld+json">
{"description":"1. Numpy / 벡터 &amp; 행렬 1.1 Numerical Python - Numpy 기본적으로 파이썬 리스트는 메모리 주소 복사 fancy index","mainEntityOfPage":{"@type":"WebPage","@id":"/ustage/2021/07/24/precourse2.html"},"author":{"@type":"Person","name":"LKH"},"@type":"BlogPosting","headline":"Precourse 수학기초","dateModified":"2021-07-24T01:20:56+09:00","datePublished":"2021-07-24T01:20:56+09:00","url":"/ustage/2021/07/24/precourse2.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>

</head>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/portfolio.png" alt="KyungHyun Lim" />
        
      </a>
      <h2 id="title">
        <a href="/">KyungHyun Lim</a>
      </h2>
      </div><p class="tagline">AI/ML/SW Developer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/KyungHyunLim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:fly1294@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><nav class="navigation about-footer condensed">
        <ul>
          
          <li>
            <a href="/" class="ctext">Home</a>
          </li>
          
        </ul>
      </nav><p class="about-footer condensed">&copy;
        2021</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/ustage/2021/07/24/precourse2.html">
    <h2 class="post-title">Precourse 수학기초</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Jul 24, 2021</div><ul class="post-categories"><li>ustage</li></ul></div>
  <div class="post">
    <h2 id="1-numpy--벡터--행렬">1. Numpy / 벡터 &amp; 행렬</h2>
<h3 id="11-numerical-python---numpy">1.1 Numerical Python - Numpy</h3>
<ul>
  <li>기본적으로 파이썬 리스트는 메모리 주소 복사
<img src="/assets/image/precourse2_1.PNG" alt="" /></li>
  <li>fancy index
<img src="/assets/image/precourse2_2.PNG" alt="" /></li>
</ul>

<h3 id="12-벡터란">1.2 벡터란?</h3>
<ul>
  <li>공간에서 한 점을 표현하는 것</li>
  <li>기준점으로 부터의 상대적 위치</li>
  <li>Hadamard product: 성분 곱
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Hadamard product
</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span> <span class="c1"># = [4, 20, 18]
</span></code></pre></div>    </div>
  </li>
  <li>norm
    <ul>
      <li>기하학적 성질이 달라짐</li>
      <li>L1 norm: Sum(변화량의 절대 값)
        <ul>
          <li>마름모 꼴</li>
          <li>Robust 학습, Lasso 회귀</li>
        </ul>
      </li>
      <li>L2 norm: 유클라디안 거리
        <ul>
          <li>원</li>
          <li>Laplace 근사, Ridge 회귀</li>
          <li>두 벡터의 각도 계산<br />
  $ cos\theta = inner(x, y) / (L2(x) \times L2(y)) $</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>내적
    <ul>
      <li>정사영된(orthogonal projection) 벡터의 길이</li>
      <li>두 벡터가 얼마나 유사한 패턴을 가지고 있는지</li>
    </ul>
  </li>
</ul>

<h3 id="13-행렬이란">1.3 행렬이란?</h3>
<ul>
  <li>벡터를 원소로 가지는 2차원 배열 (n개 행 r개열 벡터 =&gt; nxr)
    <ul>
      <li>공간상의 여러 점들을 모아둔 것</li>
    </ul>
  </li>
  <li>전치행렬 (Transpose matrix) : 행 &lt;=&gt; 열</li>
  <li>행렬곱을 통해 벡터를 다른 차원의 공간의 데이터로 변형 가능</li>
  <li>역행렬은 행과 열 숫자가 같고 행렬식이 0이 아닌 경우에만 존재
    <ul>
      <li>유사역행렬, Moore-Penrose 역행렬 A+를 이용</li>
      <li>$ n&gt;=m: A^+ = (A^TA)^{-1}A^T $
        <ul>
          <li>$ A^+A = I 만 성립 $</li>
        </ul>
      </li>
      <li>$ n&lt;=m: A^+ = A^T(A^TA)^{-1} $
        <ul>
          <li>$ AA^+ = I 만 성립 $</li>
        </ul>
      </li>
      <li>numpy 활용
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="c1"># 유사 역행렬
</span></code></pre></div>        </div>
      </li>
      <li>응용1: 연립방정식 풀기
        <ul>
          <li>$ Ax = b =&gt; x = A^+b$</li>
        </ul>
      </li>
      <li>응용2: 선형회귀 분석
        <ul>
          <li>$ X\beta = \hat y \approx y =&gt; \beta = X^+y $</li>
          <li>L2 norm을 활용해 $ \hat y , y $ 근사가능</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="2-경사하강법">2. 경사하강법</h2>
<h3 id="21-기본">2.1 기본</h3>
<ul>
  <li>미분(differentialtion): 변수의 움직임에 따른 함수값의 변화를 측정하기 위한 도구
    <ul>
      <li>$(x, f(x))$에서 접선의 기울기: 어느 방향으로 움직여야 값이 증가/감소 하는지 알 수 있음</li>
      <li>극값에 도달하면 최적화가 멈춤 =&gt; 미분 값이 0인 지점</li>
    </ul>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># 미분을 위한 파이선 라이브러리
</span> <span class="kn">import</span> <span class="nn">sympy</span> <span class="k">as</span> <span class="n">sym</span>
 <span class="kn">from</span> <span class="nn">sympy.abc</span> <span class="kn">import</span> <span class="n">x</span>

 <span class="n">sym</span><span class="p">.</span><span class="n">diff</span><span class="p">(</span><span class="n">sym</span><span class="p">.</span><span class="n">poly</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">6</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span> <span class="c1"># 해당 다항식을 x에 대해 미분하라S
</span></code></pre></div>    </div>
  </li>
  <li>편미분(partial differentiation)
    <ul>
      <li>일부 변수에 대해서만 미분
        <ul>
          <li>$ f(x,y) = x^2 + y $</li>
          <li>$ \partial x f(x,y) = 2x $</li>
        </ul>
      </li>
      <li>변수가 벡터이면?
        <ul>
          <li>그레디언트(gradient) 벡터 활용</li>
          <li>$ \nabla{f} = (\partial{x_1}, … ,\partial{x_d}) $</li>
          <li>$ -\nabla{f} $ 벡터를 그리면 극점으로 수렴</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="22-심화">2.2 심화</h3>
<ul>
  <li>선형회귀 목적식:
    <ul>
      <li>아래식을 최소화하는 $\beta$를 찾음</li>
      <li>$ \nabla \Vert y-X \beta \Vert _2 = (\partial _\beta{_1} \Vert y-X \Vert _2, …, \partial _\beta{_d} \Vert y-X \Vert _2) $</li>
      <li>$ =-{X^T(y-X\beta) \over  n\Vert{y-X\beta{^t}}\Vert{_2}} $</li>
      <li>$ \beta{^{t+1}} \leftarrow \beta{^t}-\lambda{\nabla{_\beta{||y-X\beta{^t}||_2}}} $
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># lr: 학습률, T: 학습 횟수
</span> <span class="c1"># 종료조건이 학습 횟수
</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
  <span class="n">e</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span>
  <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span> <span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">e</span>
  <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gradient</span>
</code></pre></div>        </div>
      </li>
      <li>경사하강법 사용시 학습률과, 학습 횟수를 매우 적절하게 선택해야 최적으로 수렴할 수 있음</li>
    </ul>
  </li>
  <li>convex 함수(볼록 함수)가 아닌 경우 다른 경사하강법이 필요
    <ul>
      <li>Stochastic gradient descent(SGD) 확률적 경사하강법
        <ul>
          <li>$\theta{^{t+1}}\leftarrow \theta{^t}-\hat{\nabla{_\theta \mathcal{L}(\theta{^t})}}$</li>
          <li>mini batch를 활용</li>
          <li>일부의 데이터로 조금씩 이동하므로 Non convex 함수에서 보다 효과적</li>
        </ul>
      </li>
      <li>하드웨어의 메모리적 한계도 보완 가능</li>
    </ul>
  </li>
</ul>

  </div></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/KyungHyunLim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:fly1294@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><nav class="navigation about-footer condensed">
        <ul>
          
          <li>
            <a href="/" class="ctext">Home</a>
          </li>
          
        </ul>
      </nav><p class="about-footer condensed">&copy;
        2021</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
</body>

</html>
