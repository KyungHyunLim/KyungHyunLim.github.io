<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>Batch Normalization layer</title>
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Batch Normalization layer | AI Tech Study</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Batch Normalization layer" />
<meta name="author" content="LKH" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. 기본 동작 Annotation $x_i$ : 다음 레이어에 들어가려는 입력, 0 &lt;= i &lt;= batch_size $w_{ij}$ : 해당 노드의 가중치, 0 &lt;= i, j &lt;= # of layer $\sigma$ : 활성화 함수 $\gamma , \ \beta$ : Batch norm layer에서 학습하는 파라미터 동작 순서 평균 $\mu_B$ : 미니배치에 대한 평균 분산 $\sigma_B^2$ : 미니배치에 대한 분산 Normalize = ${x_i-\mu_B \over \sigma_B} = \hat x_i$ 평균 0, 분산 1인 분포를 따르게됨 $\gamma \hat x_i + \beta = y_i$ $y_i$ : batch norm layer의 결과물 $=&gt; \sigma (BN(xw))$ Test 시에는? 총 데이터수 / 배치수 만큼의 $\gamma , \ \beta$ 존재 이 값들의 평균 활용 m: 미니배치의 수 moving average simple: 일반적인 평균 exponential: 가중치를 부여해서 나중에 구한 값에 가중치를 더줌 (과거의 값을 잊어버린다. = 초기 학습 값은 부정확하다) $E[\mu_B] $ $E[\sigma_B^2] \times {m \over m-1}$ $E[{1 \over m} \sum_{i=1}^m (x_i-\mu_B)^2] = {(m-1) \sigma_{real} \over m }$ biased estimator 데이터 전체의 평균과 분산과 같아진다! CNN 에서는? 같은 filter = 같은 $\gamma , \ \beta$ 즉, 필터 개수만큼의 $\gamma , \ \beta$ 존재 $m \times p \times q$ samples! $(p, q)$ : 출력 크기" />
<meta property="og:description" content="1. 기본 동작 Annotation $x_i$ : 다음 레이어에 들어가려는 입력, 0 &lt;= i &lt;= batch_size $w_{ij}$ : 해당 노드의 가중치, 0 &lt;= i, j &lt;= # of layer $\sigma$ : 활성화 함수 $\gamma , \ \beta$ : Batch norm layer에서 학습하는 파라미터 동작 순서 평균 $\mu_B$ : 미니배치에 대한 평균 분산 $\sigma_B^2$ : 미니배치에 대한 분산 Normalize = ${x_i-\mu_B \over \sigma_B} = \hat x_i$ 평균 0, 분산 1인 분포를 따르게됨 $\gamma \hat x_i + \beta = y_i$ $y_i$ : batch norm layer의 결과물 $=&gt; \sigma (BN(xw))$ Test 시에는? 총 데이터수 / 배치수 만큼의 $\gamma , \ \beta$ 존재 이 값들의 평균 활용 m: 미니배치의 수 moving average simple: 일반적인 평균 exponential: 가중치를 부여해서 나중에 구한 값에 가중치를 더줌 (과거의 값을 잊어버린다. = 초기 학습 값은 부정확하다) $E[\mu_B] $ $E[\sigma_B^2] \times {m \over m-1}$ $E[{1 \over m} \sum_{i=1}^m (x_i-\mu_B)^2] = {(m-1) \sigma_{real} \over m }$ biased estimator 데이터 전체의 평균과 분산과 같아진다! CNN 에서는? 같은 filter = 같은 $\gamma , \ \beta$ 즉, 필터 개수만큼의 $\gamma , \ \beta$ 존재 $m \times p \times q$ samples! $(p, q)$ : 출력 크기" />
<meta property="og:site_name" content="AI Tech Study" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-31T19:27:22+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Batch Normalization layer" />
<script type="application/ld+json">
{"description":"1. 기본 동작 Annotation $x_i$ : 다음 레이어에 들어가려는 입력, 0 &lt;= i &lt;= batch_size $w_{ij}$ : 해당 노드의 가중치, 0 &lt;= i, j &lt;= # of layer $\\sigma$ : 활성화 함수 $\\gamma , \\ \\beta$ : Batch norm layer에서 학습하는 파라미터 동작 순서 평균 $\\mu_B$ : 미니배치에 대한 평균 분산 $\\sigma_B^2$ : 미니배치에 대한 분산 Normalize = ${x_i-\\mu_B \\over \\sigma_B} = \\hat x_i$ 평균 0, 분산 1인 분포를 따르게됨 $\\gamma \\hat x_i + \\beta = y_i$ $y_i$ : batch norm layer의 결과물 $=&gt; \\sigma (BN(xw))$ Test 시에는? 총 데이터수 / 배치수 만큼의 $\\gamma , \\ \\beta$ 존재 이 값들의 평균 활용 m: 미니배치의 수 moving average simple: 일반적인 평균 exponential: 가중치를 부여해서 나중에 구한 값에 가중치를 더줌 (과거의 값을 잊어버린다. = 초기 학습 값은 부정확하다) $E[\\mu_B] $ $E[\\sigma_B^2] \\times {m \\over m-1}$ $E[{1 \\over m} \\sum_{i=1}^m (x_i-\\mu_B)^2] = {(m-1) \\sigma_{real} \\over m }$ biased estimator 데이터 전체의 평균과 분산과 같아진다! CNN 에서는? 같은 filter = 같은 $\\gamma , \\ \\beta$ 즉, 필터 개수만큼의 $\\gamma , \\ \\beta$ 존재 $m \\times p \\times q$ samples! $(p, q)$ : 출력 크기","mainEntityOfPage":{"@type":"WebPage","@id":"/ml_ai/2021/07/31/Batchnorm.html"},"author":{"@type":"Person","name":"LKH"},"@type":"BlogPosting","headline":"Batch Normalization layer","dateModified":"2021-07-31T19:27:22+09:00","datePublished":"2021-07-31T19:27:22+09:00","url":"/ml_ai/2021/07/31/Batchnorm.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>

</head>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/portfolio.png" alt="KyungHyun Lim" />
        
      </a>
      <h2 id="title">
        <a href="/">KyungHyun Lim</a>
      </h2>
      </div><p class="tagline">AI/ML/SW Developer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/KyungHyunLim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:fly1294@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><nav class="navigation about-footer condensed">
        <ul>
          
          <li>
            <a href="/" class="ctext">Home</a>
          </li>
          
        </ul>
      </nav><p class="about-footer condensed">&copy;
        2021</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/ml_ai/2021/07/31/Batchnorm.html">
    <h2 class="post-title">Batch Normalization layer</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Jul 31, 2021</div><ul class="post-categories"><li>ML_AI</li></ul></div>
  <div class="post">
    <h2 id="1-기본-동작">1. 기본 동작</h2>
<p><img src="/assets/image/BN_1.jpg" alt="" /></p>
<ul>
  <li>Annotation
    <ul>
      <li>$x_i$ : 다음 레이어에 들어가려는 입력, 0 &lt;= i &lt;= batch_size</li>
      <li>$w_{ij}$ : 해당 노드의 가중치, 0 &lt;= i, j &lt;= # of layer</li>
      <li>$\sigma$ : 활성화 함수</li>
      <li>$\gamma , \ \beta$ : Batch norm layer에서 학습하는 파라미터</li>
    </ul>
  </li>
  <li>동작 순서
    <ol>
      <li>평균 $\mu_B$ : 미니배치에 대한 평균</li>
      <li>분산 $\sigma_B^2$ : 미니배치에 대한 분산</li>
      <li>Normalize = ${x_i-\mu_B \over \sigma_B} = \hat x_i$
        <ul>
          <li>평균 0, 분산 1인 분포를 따르게됨</li>
        </ul>
      </li>
      <li>$\gamma \hat x_i + \beta = y_i$</li>
      <li>$y_i$ : batch norm layer의 결과물</li>
    </ol>
  </li>
  <li>$=&gt; \sigma (BN(xw))$</li>
  <li>Test 시에는?
    <ul>
      <li>총 데이터수 / 배치수 만큼의 $\gamma , \ \beta$ 존재</li>
      <li>이 값들의 평균 활용
        <ul>
          <li>m: 미니배치의 수</li>
          <li>moving average
            <ul>
              <li>simple: 일반적인 평균</li>
              <li>exponential: 가중치를 부여해서 나중에 구한 값에 가중치를 더줌 (과거의 값을 잊어버린다. = 초기 학습 값은 부정확하다)</li>
            </ul>
          </li>
          <li>$E[\mu_B] $</li>
          <li>$E[\sigma_B^2] \times {m \over m-1}$
            <ul>
              <li>$E[{1 \over m} \sum_{i=1}^m (x_i-\mu_B)^2] = {(m-1) \sigma_{real} \over m }$</li>
              <li>biased estimator</li>
              <li>데이터 전체의 평균과 분산과 같아진다!</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>CNN 에서는?
    <ul>
      <li>같은 filter = 같은 $\gamma , \ \beta$
        <ul>
          <li>즉, 필터 개수만큼의 $\gamma , \ \beta$ 존재</li>
        </ul>
      </li>
      <li>$m \times p \times q$ samples!
        <ul>
          <li>$(p, q)$ : 출력 크기</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="2-의미-및-사용하는-이유">2. 의미 및 사용하는 이유</h2>
<ul>
  <li>Batch안의 데이터마다 $x_i$ 값이 일정하지 않음
    <ul>
      <li>즉, $x_i$ 가 랜덤하다고 볼 수 있음 (랜덤분포)</li>
    </ul>
  </li>
  <li>평균과 분산을 구해 빼고 나누어주고, 학습한 파라미터를 다시 곱하고 더해줌
    <ul>
      <li>Randomvariable : 랜덤하게 퍼져있는 알갱이들</li>
      <li>Normalize 단계 까지 : 한군데로 모아줌</li>
      <li>마지막 단계 : 다시 뿌려줌!</li>
      <li>어디어 어떻게 뿌릴까를 학습하는 것!</li>
    </ul>
  </li>
  <li>활성화 함수가 Sigmoid 라면?
<img src="/assets/image/BN_2.jpg" alt="" />
    <ul>
      <li>2번에 뿌려준다면? 거의 선형함수와 동일, 비선형성을 잃어 버릴 수 있음</li>
      <li>너무 끝에 치우쳐 뿌려준다면? gradient가 없음</li>
      <li>즉, 적절하게 뿌려주기 위한 학습
        <ul>
          <li>1, 2 번 영역</li>
          <li>비선형성이 존재하고, gradient 또한 적정수준 존재!</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>딥러닝 모델이 적절한지 파악하는 방법
    <ul>
      <li>$\gamma , \ \beta$ 의 초기 값: 1, 0 근처</li>
      <li>0 근처에서 뿌려보면서 loss가 작아지는 방향으로 결정
        <ul>
          <li>시작점을 조절해 유도가능</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>효과!
    <ul>
      <li>vanishing gradient 보완 가능</li>
      <li>빠른학습 (논문에 따르면 14배)</li>
      <li>learning rate 키워도 된다!</li>
      <li>Dropout이 필요 없음</li>
    </ul>
  </li>
</ul>

<h2 id="3-참조">3. 참조</h2>
<ul>
  <li>그래프 그리기: https://www.desmos.com/calculator/</li>
  <li>그림: powerpoint</li>
  <li>강의: https://www.youtube.com/watch?v=m61OSJfxL0U</li>
</ul>

  </div></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/KyungHyunLim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:fly1294@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><nav class="navigation about-footer condensed">
        <ul>
          
          <li>
            <a href="/" class="ctext">Home</a>
          </li>
          
        </ul>
      </nav><p class="about-footer condensed">&copy;
        2021</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
</body>

</html>
