---
layout: post
title:  "Beam search and BLEU score"
date:   2021-09-08 12:00:22
categories: [ML_AI]
use_math: true
---
BLEU score가 번역 문장 평가에 있어서 갖는 단점은 무엇이 있을까요?
# 1. Beam search
## 1.1 Greedy decoding
* 다음에 나올 단어로 가장 확률이 높은 단어만으로 학습을 하는 것
* 즉, 가장 좋아보이는 단어를 그때 그때 선택하는 greedy 형태
* 한번 잘 못 선택하면 뒤로 돌아갈 수 없음

## 1.2 Exhaustive search
* $P(y \vert x) = P(y_1 \vert x)P(y_2 \vert y_1, x)... $
* 전체적인 문장의 확률을 고려할 수 있음
* 하지만 디코더의 각 time step마다 $V^t$ 개의 가능한 경우의 수를 검토해야함, 이것은 시간복잡도가 $O(V^t)$ 로 매우 비효율적

## 1.3 Beam search
* Greedy와 Exhaustive의 사이에 있는 방법
* Core idea: 정해진 k개 경우의 수(hypothesis)만 검토하는 방법
	* 보통 5~10개
* $score(y_1, ..., y_t)=logP_{LM}(y_1,...,y_t \vert x)= \sum_{i=1}^t logP_{LM} (y_t \vert y_1, ...,y_{i-1},x)$
	* log => 단조증가, 큰값은 log를 취해도 다른 수에비해 큰값으로 유지됨
	* 매 time step 마다 k개 tracking
* Process  
	![](/assets/image/ustagelv2/w5_d3_8.png)
	* 확률이 높은 K개의 단어 선택
	* 즉, 매 time step마다 K^2개의 후보만 searching 후 확률이 가장 높은 K개의 후보만 선택
	* hypothesis들이 각각 다른 시점에서 < END > 를 생성할 수 있음
		* 다른 시점에 생성에 종료됨
		* 또는 Stopping criterion을 활용해 강제 종료 가능
* 상대적으로 길이가 길수록 joint probability가 작아짐

# 2. BLEU score

