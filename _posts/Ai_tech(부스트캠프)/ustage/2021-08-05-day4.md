---
layout: post
title:  "Week1 - 3 일차"
date:   2021-08-05 21:54:56
categories: [ustage]
use_math: true
---

## 1. 면접일정

## 2. 개인학습
 * 통계론
    * 기대값?     
        * $ \mathbb E_{X \sim P(\mathcal X)} [f(X)] = \int_{\mathcal X} f(X)P(\mathcal X)dX $
        * $ \mathbb E_{X \sim P(\mathcal X)} [f(X)] = \sum_{x \in \mathcal X} f(x)P(\mathcal X) $
        * 분산, 첨도, 공분산 등 여러 통계량 계산 가능
            * $ \mathbb{V} (X)=\mathbb{E}_{X \sim P(X)} [(X-\mathbb{E}[X])^2] $
            * $ Skewness(X)=\mathbb{E}[({X-\mathbb{E}[X] \over \sqrt{\mathbb{V}(X)}})^3] $
            * $ Cov(X_1, X_2)=\mathbb{E}_{X_1, X_2 \sim P(X_1, X_2)}[(X_1 - \mathbb{E}[X_1])(X_2 - \mathbb{E}[X_2])] $
    * 몬테카를로 샘플링
        * 데이터의 확률분포를 모르는 경우 사용, 샘플링을 통해 기대값 계산
        * 이산/연속 상관없이 동작
        * 독립추출만 보장된다면 law of largenumber에 의해 수렴성 보장
        * $ \mathbb E_{X \sim P(X)}[f(X)] \approx {1 \over N} \sum_{i=1}^N f(x^i),\ x^i \sim^{i.i.d.} P(X) $

 * CNN 첫걸음
    * MLP: Fully connected 구조
		* 입력과 가중치의 내적을 이용해 계산
		* $h_i=\sigma (\sum_{j=1}^p W_{ij} X_j)$
	* CNN: Kernel이라는 고정된 가중치 행렬 사용
		* Kernel 크기 만큼 움직여가며 계산
			* parameter size를 줄일 수 있음
		* $h_i=\sigma (\sum_{j=1}^k V_j X_{i+j-1})$
		* Convolution in cnn (cross-correlation)
			* kernel을 이용해 국소적으로 증폭 또는 감소시켜 정보를 추출(필터링)
			* Continuous: $[f*g] (x) = \int_{R^d} f(z) g(x+z)dz = \int_{R^d} f(x+z) g(z)dz = [g*f](x)$			
			* Discrete: $[f*g] (i) = \sum_a f(a)g(i+a) = \sum_a f(i+a)g(a) = [g*f] (i)$
		* local: 일정 부분에 적용
		* translation invariant: 커널의 크기가 변하지 않음
	* 고차원에서 Conv'
		* 2d: $[f*g] (i,j) = \sum_{p,q} f(p,q)g(i+p,j+q)$
		* 3d: $[f*g] (i,j,k) = \sum_{p,q,r} f(p,q,r)g(i+p,j+q,k+r)$
		* 동일하게 커널은 바뀌지 않는다
	* 입출력 크기 변화
		* $(H, W) \rightarrow (K_H, K_W) \rightarrow (O_H, O_W)
		* $O_H = H - K_H + 1$
		* $O_W = W - K_W + 1$
	* 2d-CNN에서 입출력 크기 변화
		* $(H, W, C) \rightarrow (K_H, K_W, C) \rightarrow (O_H, O_W, 1)
		* 커널이 $O_C$ 개가 되면 (O_H, O_W, O_C)
	* Backpropagation
		* ${\partial \over \partial x} [f*g](x) = \int f(y)g(x-y)dy $
		* $= \int f(y) {\partial g \over \partial x} = [f*g'](x) $ 

## 3. 선택과제 3번

 * TODO 4, TODO 5
    * pdf를 이용해 정규분포 그리기
    * 주어진 관찰 값에서 가능도 출력, pdf(1)

 ```python
 plt.plot(x, sp.stats.norm(loc=-1).pdf(x), ls="-.")
 plt.plot(x, sp.stats.norm(loc=0).pdf(x), ls="--")
 plt.plot(x, sp.stats.norm(loc=1).pdf(x), ls="-")

 print('mu=-1: likelihood at x_0=1 is {:.4f}'.format(p1))
 print('mu=0: likelihood at x_0=1 is {:.4f}'.format(p2))
 print('mu=1: likelihood at x_0=1 is {:.4f}'.format(p3))
 ```

 ## 4. 필수퀴즈 10
 * About RNN
