---
layout: post
title:  "Week2 - 1일차"
date:   2021-08-09 20:22:30
categories: [ustage]
use_math: true
---

## 1. 개인학습
* 딥러닝 기본 용어 설명
	* 세부 포함 관계
		* AI > ML > DL
		* Mimic human intelligence / Data-driven approach / Neural networks
	* Key of DL
		* Data
		* Model 
		* Loss
		* Algorithm (Optimization): SGD, Adam, RMSprop, ...
	* History
		* 2012 - AlexNet
		* 2013 - DQN
		* 2014 - Encoder/Decoder, Adam
		* 2015 - GAN, ResNet
		* 2017 - Transformer (Attention Is All You Need)
		* 2018 - Bert
		* 2019 - GPT-X
		* 2020 - Self-Supervised Learning (SimCLR)
	
* 뉴럴 네트워크 - MLP
	* Linear Neral Networks  
		![](/assets/image/ustage/w2_day1_1.png)
		* Backpropagation: 어느 방향으로 움직여야 Loss가 줄어드는지?
		* W와 b에 대한 편미분 활용
			* $w \leftarrow w-lr {\partial L \over \partial w}$
			* $b \leftarrow b-lr {\partial L \over \partial b}$
		* 행렬의 곱은 공간상의 전환  
		![](/assets/image/ustage/w2_day1_2.png)
		* 활성화 함수를 활용한 비선형성 부여
			* sigmoid, tanh, relu 등
	* Multi-Layer Perceptron
		![](/assets/image/ustage/w2_day1_3.png)
		* Loss function
			* MSE: Mean square error => Outlier가 있을때 망가질 수 있음
			* CE: Cross-entrophy => 해당 클래스 예측 값을 높이는 효과
			* MLE: Probabilistic Task
		
* 데이터 시각화
	* Overview
		* 고려할 Task!
			* 목적: 왜 시각화?
			* 독자: 대상
			* 데이터: 어떤 데이터?
			* 스토리: 어떤 흐름으로 전달?
			* 방법: 전달하고자 하는 내용과 맞나?
			* 디자인: UI에서 만족스로운 디자인?
		* 모범 사례를 통해 익히자!
		* 추천
			* Visualization Analysis & Design
			* Fundamentals of Data visualization
			* https://observablehq.com
			* https://dataviztoday.com
			* https://ieeevis.org/year/2021/welcome
	* 시각화 요소
		* 수많은 데이터셋
			* 정형 데이터: csv, tsv
				* 가장 쉽게 시각화 가능
				* 통계적 특성 및 feature 사이 관계
				* 데이터 간 관계
				* 데이터 간 비교
			* 시계열 데이터
				* 추세(Trend), 계절성(Seasonality), 주기성(Cycle) 등
			* 지리 데이터
				* 지도 정보 + 정보간 조화
				* 거리, 경로, 분포 등
			* 관계형 데이터
				* Graph visualization / Network visualization
				* 객체는 Node로 관계는 Link로
			* 계층적 데이터
				* 포함관계가 분명한 데이터
				* Tree, Treemap, Sunburst 등
			* 다양한 비정형 데이터
		* 4가지 분류
			* 수치형: 연속형/ 이산형
			* 범주형
				* 명목형(nominal - 혈액형, 종교, ...)
				* 순서형(ordinal - 학년, 별점, 등급, ...)
	* 시각화 이해하기
		* 기본 요소
			* mark: 점, 선, 면
			* channel: 각 mark를 변경할 수 있는 요소들
				* 위치, 색, 면적, 모양, 기울기 등
		* Pre-attentive attribute
			* 주의를 주지 않아도 인지하게 되는 요소
			* 동시에 사용하면 인지하기 어려움
		* Tip!
			* Color를 잘 활용하자!
	* 실습

## 2. 필수과제
* MNIST 데이터, MLP, CrossEntropyLoss()
* MLP 모델 설계
```python
# xdim: 입력 데이터 크기
# hdim: 히든레이어 노드 수
# ydim: 출력 크기(분류할 클래스 수)

self.lin_1 = nn.Linear(xdim, hdim)
self.lin_2 = nn.Linear(hdim, ydim)
```

* 모델 평가 함수
```python
# 모델 예측 계산, forward
model_pred = model(torch.reshape(batch_in, (-1, 1 * 28 * 28)).to(device))

# 가장 큰 값의 인덱스로 최종 분류
_,y_pred = torch.max(model_pred.data,1)

# torch.eq: element-wise로 두 Tensor 비교, 같으면 True, 다르면 False
# torch.ne: eq와 반대, 같으면 False, 다르면 True
# 맞춘 갯수 계산
n_correct += (torch.eq(y_trgt, y_pred)).sum().item()
```

* 모델 훈련
```python
# Forward path
y_pred = M.forward(batch_in.view(-1, 28*28).to(device))
loss_out = loss(y_pred,batch_out.to(device))

# Update
# 그래디언트 초기화
	# 파이토치는 그래디언트가 누적 됨으로 이전 배치의 그래디언트 값이 잔재
	# 배치마다 초기화 필요
optm.zero_grad()
# 역전파 계산
loss_out.backward()
# Weight 업데이트
optm.step()
```

## 3. 피어세션
1. 강의 요약
2. 과제 리뷰
3. 코딩 테스트 알고리즘 이론 스터디
	* 정규표현식
		* re 라이브러리
	* 매칭알고리즘
		* 단순비교
		* KMP 알고리즘: 접두사와 접미사 활용
		* 보이어-무어 알고리즘: KMP 개선/ 뒤에서 부터 확인
		* 라빈-카프 알고리즘: 해쉬함수 사용
	* 풀어야할 문제
		* 1013, 5525, 16916, 1786

## 4. 알고리즘 문제 풀이
* [코드](https://github.com/KyungHyunLim/Algorithms/blob/main/BAEKJOON/baek_5525.cpp)
* [코드](https://github.com/KyungHyunLim/Algorithms/blob/main/BAEKJOON/baek_1013.cpp)
 