---
layout: post
title:  "Week6 - Day2"
date:   2021-09-07 20:22:30
categories: [ustage]
---

## 1. 개인학습
* [RNN](https://kyunghyunlim.github.io/ml_ai/2021/08/12/rnn.html) - 내용보강
* [RNN NLP, LSTM, GRU](https://kyunghyunlim.github.io/ml_ai/2021/09/07/rnnplus.html)

## 2. 필수과제
* RNN
    * 펄플렉서티(perplexity) ppl  
    낮을 수로 좋은 값, 헷갈리는 정도를 의미한다. bi-gram의 경우 ppl을 계산할 때 분모에 이전단어가 고정되고 다음 단어가 나올 확률을 곱해주게 된다.   
    즉, ppl은 낮을 수록 좋은 값을 가지기 때문에, 이전 단어에서 나올 수 있는 다음 단어의 확률이 높을 수록 성능이 높은 것이다. 
    * 왜 optimizer를 따로 쓰지 않았나?
    * 현재 코드는 `train`, `dev`, `test` 데이터를 모두 dictionary 에 포함하고 있습니다. 이때 발생할 수 있는 문제점은 무엇일까요?